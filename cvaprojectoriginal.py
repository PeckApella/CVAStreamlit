# -*- coding: utf-8 -*-
"""CVAProjectOriginal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zeeCYiPYY0ZiZP2jvbHQqEOqJ2SHBf2Z

# **The code we used to preprocess and crop the training data**
"""

'''
import os
import cv2

# Load the pre-trained face detection model
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Input folder containing the images
input_folder = "C:/Users/hp/OneDrive/Desktop/CVA_Data/Timothee_Chalamet/"

# Output folder to save cropped faces
output_folder = "C:/Users/hp/OneDrive/Desktop/CVA_Data/Timothee_Faces_Cropped/"

# Create the output folder if it doesn't exist
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Iterate over each image file in the input folder
for filename in os.listdir(input_folder):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # Adjust file extensions as needed
        # Load the image
        image_path = os.path.join(input_folder, filename)
        image = cv2.imread(image_path)

        # Check if the image was loaded successfully
        if image is None:
            print(f"Error: Unable to read {filename}")
            continue

        # Convert the image to grayscale
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Detect faces in the image
        faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # Crop and save each detected face
        for i, (x, y, w, h) in enumerate(faces):
            face = image[y:y+h, x:x+w]
            output_path = os.path.join(output_folder, f'{filename}_face_{i}.jpg')
            cv2.imwrite(output_path, face)
            '''

from google.colab import drive
drive.mount('/content/gdrive')

'''from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive

# Authenticate and create the PyDrive client
gauth = GoogleAuth()
gauth.LocalWebserverAuth()  # Opens a new window/tab for authentication
drive = GoogleDrive(gauth)

# ID of the folder containing the images (CroppedFaces folder)
folder_id = 'your_folder_id_here'

# List all files in the folder
file_list = drive.ListFile({'q': f"'{folder_id}' in parents and trashed=false"}).GetList()

# Download each file
for file in file_list:
    file.GetContentFile(file['title'])  # Download the file and save it in the current directory
    print(f"Downloaded: {file['title']}")'''

!pip install streamlit

"""# **Without LOOCV**"""

from google.colab import drive
import os
import cv2
import streamlit as st
import numpy as np
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

drive.mount('/content/gdrive')

def load_images_from_subfolder(folder, target_size=(100, 100)):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale
        if img is not None:
            img = cv2.resize(img, target_size)  # Resize the image to a fixed size
            images.append(img)
    return images

def load_images_from_folder(main_folder):
    images = []
    labels = []
    for root, dirs, files in os.walk(main_folder):
        for dir_name in dirs:
            folder_path = os.path.join(root, dir_name)
            celebrity_images = load_images_from_subfolder(folder_path)
            images.extend(celebrity_images)
            labels.extend([dir_name] * len(celebrity_images))  # Assign label based on folder name
    return images, labels

main_folder = '/content/gdrive/MyDrive/CroppedFaces'

images = []
labels = []
for root, dirs, files in os.walk(main_folder):
    for dir_name in dirs:
        folder_path = os.path.join(root, dir_name)
        celebrity_images = load_images_from_subfolder(folder_path)
        images.extend(celebrity_images)
        labels.extend([dir_name] * len(celebrity_images))  # Assign label based on folder name

images = np.array(images)
labels = np.array(labels)

images_flattened = images.reshape(len(images), -1)

X_train, X_test, y_train, y_test = train_test_split(images_flattened, labels, test_size=0.2, random_state=42)

clf = svm.SVC(kernel='linear')

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

"""# **LOOCV**"""

from google.colab import drive
import os
import cv2
import numpy as np
from sklearn import svm
from sklearn.model_selection import LeaveOneOut

drive.mount('/content/gdrive')

def load_images_from_subfolder(folder, target_size=(100, 100)):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale
        if img is not None:
            img = cv2.resize(img, target_size)  # Resize the image to a fixed size
            images.append(img)
    return images

def load_images_from_folder(main_folder):
    images = []
    labels = []
    for root, dirs, files in os.walk(main_folder):
        for dir_name in dirs:
            folder_path = os.path.join(root, dir_name)
            celebrity_images = load_images_from_subfolder(folder_path)
            images.extend(celebrity_images)
            labels.extend([dir_name] * len(celebrity_images))  # Assign label based on folder name
    return images, labels

main_folder = '/content/gdrive/MyDrive/CroppedFaces'

images = []
labels = []
for root, dirs, files in os.walk(main_folder):
    for dir_name in dirs:
        folder_path = os.path.join(root, dir_name)
        celebrity_images = load_images_from_subfolder(folder_path)
        images.extend(celebrity_images)
        labels.extend([dir_name] * len(celebrity_images))  # Assign label based on folder name

images = np.array(images)
labels = np.array(labels)

images_flattened = images.reshape(len(images), -1)

# Perform Leave-One-Out Cross-Validation (LOOCV)
loo = LeaveOneOut()
accuracies = []
c = 1
for train_index, test_index in loo.split(images_flattened):
    c+=1
    X_train, X_test = images_flattened[train_index], images_flattened[test_index]
    y_train, y_test = labels[train_index], labels[test_index]

    # Train the model on the training set
    clf = svm.SVC(kernel='linear')
    clf.fit(X_train, y_train)

    # Evaluate the model on the test set
    accuracy = clf.score(X_test, y_test)
    accuracies.append(accuracy)
    print(c)
# Calculate the mean accuracy across all iterations
mean_accuracy = np.mean(accuracies)
print(f"Mean Accuracy using Leave-One-Out Cross-Validation: {mean_accuracy * 100:.2f}%")

# Save the trained model to Google Drive
from joblib import dump
model_save_path = '/content/gdrive/MyDrive/trained_model.joblib'
dump(clf, model_save_path)
print("Model saved successfully to Google Drive.")

"""# **Testing**

# **Saving the model**
"""

from google.colab import drive
import joblib
drive.mount('/content/gdrive')
model_save_path = '/content/gdrive/MyDrive/trained_model.joblib'
clf = joblib.load(model_save_path)
print("Model loaded successfully from Google Drive.")

from google.colab import files
import cv2
import numpy as np
import pickle
def preprocess_image(img, target_size=(100, 100)):
    img_resized = cv2.resize(img, target_size)
    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
    return img_gray

def crop_faces(image):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    cropped_faces = []
    for (x, y, w, h) in faces:
        cropped_faces.append(image[y:y+h, x:x+w])
    return cropped_faces

def classify_image(image):
    processed_image = preprocess_image(image)
    flattened_image = processed_image.flatten().reshape(1, -1)
    predicted_label = clf.predict(flattened_image)
    decision_values = clf.decision_function(flattened_image)
    probabilities = np.exp(decision_values) / np.sum(np.exp(decision_values), axis=1, keepdims=True)
    return predicted_label[0], probabilities[0]

uploaded_files = files.upload()

file_name = list(uploaded_files.keys())[0]
uploaded_image = cv2.imread(file_name)

cropped_faces = crop_faces(uploaded_image)

for i, face in enumerate(cropped_faces):
    print(f"Classifying face {i + 1}:")
    predicted_celebrity, probability_distribution = classify_image(face)
    celebrity_names = {
        0: "Dwayne",
        1: "Timothee",
        2: "Henry",
        3: "Ryan"
    }
    for i, prob in enumerate(probability_distribution):
        celebrity_name = celebrity_names[i]
        print(f"Probability of {celebrity_name}: {prob:.2f}")

    max_probability_index = np.argmax(probability_distribution)
    max_probability_celebrity = celebrity_names[max_probability_index]

    print(f"This looks like {max_probability_celebrity} the most!\n")




import matplotlib.pyplot as plt

plt.bar(celebrity_names.values(), probability_distribution)

for i, prob in enumerate(probability_distribution):
    plt.text(i, prob + 0.01, f"{prob:.2f}", ha='center', va='bottom', color='red')

plt.title("Celebrity Identification")
plt.xlabel("Celebrity")
plt.ylabel("Probability")

plt.show()

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
import cv2
from google.colab.patches import cv2_imshow

def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'Capture';
            div.appendChild(capture);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();

            // Resize the output to fit the video element.
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            // Wait for Capture to be clicked.
            await new Promise((resolve) => capture.onclick = resolve);

            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
        ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

# Take a photo using the webcam
image_path = take_photo()

# Read the captured image using OpenCV
image = cv2.imread(image_path)

# Display the captured image
cv2_imshow(image)

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
import cv2
import os

def take_photo(quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'Capture';
            div.appendChild(capture);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();

            // Resize the output to fit the video element.
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            // Wait for Capture to be clicked.
            await new Promise((resolve) => capture.onclick = resolve);

            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
        ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    return binary

# Take a photo using the webcam
image_data = take_photo()

# Decode the image data
image_np = np.frombuffer(image_data, np.uint8)
image = cv2.imdecode(image_np, cv2.IMREAD_COLOR)

# Save the captured image as "image.jpg"
image_file_path = '/content/image.jpg'
cv2.imwrite(image_file_path, image)

# Display the captured image
cv2_imshow(image)

# Print the file path where the image is saved
print("Image saved as:", image_file_path)

import cv2
import numpy as np
import pickle

def preprocess_image(img, target_size=(100, 100)):
    img_resized = cv2.resize(img, target_size)
    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
    return img_gray

def crop_faces(image):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    cropped_faces = []
    for (x, y, w, h) in faces:
        cropped_faces.append(image[y:y+h, x:x+w])
    return cropped_faces

def classify_image(image):
    processed_image = preprocess_image(image)
    flattened_image = processed_image.flatten().reshape(1, -1)
    predicted_label = clf.predict(flattened_image)
    decision_values = clf.decision_function(flattened_image)
    probabilities = np.exp(decision_values) / np.sum(np.exp(decision_values), axis=1, keepdims=True)
    return predicted_label[0], probabilities[0]

# Load the image
image_path = '/content/image.jpg'
uploaded_image = cv2.imread(image_path)

# Crop faces from the uploaded image
cropped_faces = crop_faces(uploaded_image)

# Classify each face in the uploaded image
for i, face in enumerate(cropped_faces):
    print(f"Classifying face {i + 1}:")
    predicted_celebrity, probability_distribution = classify_image(face)
    celebrity_names = {
        0: "Dwayne",
        1: "Timothee",
        2: "Henry",
        3: "Ryan"
    }
    for i, prob in enumerate(probability_distribution):
        celebrity_name = celebrity_names[i]
        print(f"Probability of {celebrity_name}: {prob:.2f}")

    max_probability_index = np.argmax(probability_distribution)
    max_probability_celebrity = celebrity_names[max_probability_index]

    print(f"This looks like {max_probability_celebrity} the most!\n")

import matplotlib.pyplot as plt

plt.bar(celebrity_names.values(), probability_distribution)

for i, prob in enumerate(probability_distribution):
    plt.text(i, prob + 0.01, f"{prob:.2f}", ha='center', va='bottom', color='red')

plt.title("Celebrity Identification")
plt.xlabel("Celebrity")
plt.ylabel("Probability")

plt.show()

st.pyplot(plt)